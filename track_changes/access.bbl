% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{trabelsi2021pose}
A.~Trabelsi, M.~Chaabane, N.~Blanchard, and R.~Beveridge, ``A pose proposal and
  refinement network for better 6d object pose estimation,'' in
  \emph{Proceedings of the IEEE/CVF winter conference on applications of
  computer vision}, 2021, pp. 2382--2391.

\bibitem{hoang2023grasp}
D.-C. Hoang, A.-N. Nguyen, V.-D. Vu, D.-Q. Vu, V.-T. Nguyen, T.-U. Nguyen,
  C.-T. Tran, K.-T. Phan, and N.-T. Ho, ``Grasp configuration synthesis from 3d
  point clouds with attention mechanism,'' \emph{Journal of Intelligent and
  Robotic Systems}, vol. 109, no.~3, p.~71, 2023.

\bibitem{wang2021gdr}
G.~Wang, F.~Manhardt, F.~Tombari, and X.~Ji, ``Gdr-net: Geometry-guided direct
  regression network for monocular 6d object pose estimation,'' in \emph{Proc.
  IEEE/CVF Conf. Comput. Vis. Pattern Recognit.}, 2021, pp. 16\,611--16\,621.

\bibitem{hoang2022context}
D.-C. Hoang, J.~A. Stork, and T.~Stoyanov, ``Context-aware grasp generation in
  cluttered scenes,'' in \emph{2022 International Conference on Robotics and
  Automation (ICRA)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2022, pp.
  1492--1498.

\bibitem{wang2019densefusion}
C.~Wang, D.~Xu, Y.~Zhu, R.~Mart{\'\i}n-Mart{\'\i}n, C.~Lu, L.~Fei-Fei, and
  S.~Savarese, ``Densefusion: 6d object pose estimation by iterative dense
  fusion,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, 2019, pp. 3343--3352.

\bibitem{hoang2024collision}
D.-C. Hoang, A.-N. Nguyen, C.-M. Nguyen, A.-B. Phi, Q.-T. Duong, K.-D. Tran,
  V.-A. Trinh, V.-D. Tran, H.-N. Pham, P.-Q. Ngo \emph{et~al.},
  ``Collision-free grasp detection from color and depth images,'' \emph{IEEE
  Transactions on Artificial Intelligence}, 2024.

\bibitem{zakharov2019dpod}
S.~Zakharov, I.~Shugurov, and S.~Ilic, ``Dpod: 6d pose object detector and
  refiner,'' in \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, 2019, pp. 1941--1950.

\bibitem{tan2024attention}
P.~X. Tan, D.-C. Hoang, A.-N. Nguyen, V.-T. Nguyen, V.-D. Vu, T.-U. Nguyen,
  N.-A. Hoang, K.-T. Phan, D.-T. Tran, D.-Q. Vu \emph{et~al.},
  ``Attention-based grasp detection with monocular depth estimation,''
  \emph{IEEE Access}, 2024.

\bibitem{billings2019silhonet}
G.~Billings and M.~Johnson-Roberson, ``Silhonet: An rgb method for 6d object
  pose estimation,'' \emph{IEEE Robotics and Automation Letters}, vol.~4,
  no.~4, pp. 3727--3734, 2019.

\bibitem{hoang2024object}
D.-C. Hoang, P.~X. Tan, A.-N. Nguyen, D.-Q. Vu, V.-D. Vu, T.-U. Nguyen, Q.-T.
  Duong, V.-T. Nguyen, N.-A. Hoang, K.-T. Phan \emph{et~al.}, ``Object pose
  estimation using color images and predicted depth maps,'' \emph{IEEE Access},
  2024.

\bibitem{peng2019pvnet}
S.~Peng, Y.~Liu, Q.~Huang, X.~Zhou, and H.~Bao, ``Pvnet: Pixel-wise voting
  network for 6dof pose estimation,'' in \emph{Proceedings of the IEEE/CVF
  International Conference on Computer Vision}, 2019, pp. 4561--4570.

\bibitem{hoang2025attention}
D.-C. Hoang, A.-N. Nguyen, T.-U. Nguyen, N.-A. Hoang, V.-D. Vu, D.-Q. Vu, P.-Q.
  Ngo, K.-T. Phan, D.-T. Tran, V.-T. Nguyen \emph{et~al.}, ``Attention-based
  hand pose estimation with voting and dual modalities,'' \emph{Engineering
  Applications of Artificial Intelligence}, vol. 139, p. 109526, 2025.

\bibitem{marullo20236d}
G.~Marullo, L.~Tanzi, P.~Piazzolla, and E.~Vezzetti, ``6d object position
  estimation from 2d images: A literature review,'' \emph{Multimedia Tools and
  Applications}, vol.~82, no.~16, pp. 24\,605--24\,643, 2023.

\bibitem{du2021vision}
G.~Du, K.~Wang, S.~Lian, and K.~Zhao, ``Vision-based robotic grasping from
  object localization, object pose estimation to grasp estimation for parallel
  grippers: a review,'' \emph{Artificial Intelligence Review}, vol.~54, no.~3,
  pp. 1677--1734, 2021.

\bibitem{cho2024integration}
S.-W. Cho, Y.-H. Lim, K.-M. Seo, and J.~Kim, ``Integration of eye-tracking and
  object detection in a deep learning system for quality inspection analysis,''
  \emph{Journal of Computational Design and Engineering}, vol.~11, no.~3, pp.
  158--173, 2024.

\bibitem{hoang2024graspability}
D.-C. Hoang, A.-N. Nguyen, V.-D. Vu, T.-U. Nguyen, D.-Q. Vu, P.-Q. Ngo, N.-A.
  Hoang, K.-T. Phan, D.-T. Tran, V.-T. Nguyen \emph{et~al.},
  ``Graspability-aware object pose estimation in cluttered scenes,'' \emph{IEEE
  Robotics and Automation Letters}, 2024.

\bibitem{hoang2022voting}
D.-C. Hoang, J.~A. Stork, and T.~Stoyanov, ``Voting and attention-based pose
  relation learning for object pose estimation from 3d point clouds,''
  \emph{IEEE Robotics and Automation Letters}, vol.~7, no.~4, pp. 8980--8987,
  2022.

\bibitem{vu2024occlusion}
V.-D. Vu, D.-D. Hoang, P.~X. Tan, V.-T. Nguyen, T.-U. Nguyen, N.-A. Hoang,
  K.-T. Phan, D.-T. Tran, D.-Q. Vu, P.-Q. Ngo \emph{et~al.}, ``Occlusion-robust
  pallet pose estimation for warehouse automation,'' \emph{IEEE Access}, 2024.

\bibitem{chen2016innovative}
L.-C. Chen, D.-C. Hoang, H.-I. Lin, and T.-H. Nguyen, ``Innovative methodology
  for multi-view point cloud registration in robotic 3d object scanning and
  reconstruction,'' \emph{Applied Sciences}, vol.~6, no.~5, p. 132, 2016.

\bibitem{chao2021dexycb}
Y.-W. Chao, W.~Yang, Y.~Xiang, P.~Molchanov, A.~Handa, J.~Tremblay, Y.~S.
  Narang, K.~Van~Wyk, U.~Iqbal, S.~Birchfield \emph{et~al.}, ``Dexycb: A
  benchmark for capturing hand grasping of objects,'' in \emph{Proc. IEEE/CVF
  Conf. Comput. Vis. Pattern Recognit.}, 2021, pp. 9044--9053.

\bibitem{hoang2024multi}
D.-C. Hoang, P.~X. Tan, A.-N. Nguyen, D.-Q. Vu, V.-D. Vu, T.-U. Nguyen, N.-A.
  Hoang, K.-T. Phan, D.-T. Tran, V.-T. Nguyen \emph{et~al.}, ``Multi-modal
  hand-object pose estimation with adaptive fusion and interaction learning,''
  \emph{IEEE Access}, 2024.

\bibitem{garcia2018first}
G.~Garcia-Hernando, S.~Yuan, S.~Baek, and T.-K. Kim, ``First-person hand action
  benchmark with rgb-d videos and 3d hand pose annotations,'' in \emph{Proc.
  IEEE/CVF Conf. Comput. Vis. Pattern Recognit.}, 2018, pp. 409--419.

\bibitem{llop2022benchmarking}
I.~Llop-Harillo, J.~L. Iserte, and A.~Perez-Gonzalez, ``Benchmarking
  anthropomorphic hands through grasping simulations,'' \emph{Journal of
  Computational Design and Engineering}, vol.~9, no.~2, pp. 330--342, 2022.

\bibitem{hoang2016sub}
D.-C. Hoang, L.-C. Chen, and T.-H. Nguyen, ``Sub-obb based object recognition
  and localization algorithm using range images,'' \emph{Measurement Science
  and Technology}, vol.~28, no.~2, p. 025401, 2016.

\bibitem{wang20216d}
H.~Wang, H.~Wang, and C.~Zhuang, ``6d pose estimation from point cloud using an
  improved point pair features method,'' in \emph{2021 7th International
  Conference on Control, Automation and Robotics (ICCAR)}.\hskip 1em plus 0.5em
  minus 0.4em\relax IEEE, 2021, pp. 280--284.

\bibitem{li2019cdpn}
Z.~Li, G.~Wang, and X.~Ji, ``Cdpn: Coordinates-based disentangled pose network
  for real-time rgb-based 6-dof object pose estimation,'' in \emph{Proceedings
  of the IEEE/CVF international conference on computer vision}, 2019, pp.
  7678--7687.

\bibitem{hoang2020panoptic}
D.-C. Hoang, A.~J. Lilienthal, and T.~Stoyanov, ``Panoptic 3d mapping and
  object pose estimation using adaptively weighted semantic information,''
  \emph{IEEE Robotics and Automation Letters}, vol.~5, no.~2, pp. 1962--1969,
  2020.

\bibitem{hoang2019object}
D.-C. Hoang, T.~Stoyanov, and A.~J. Lilienthal, ``Object-rpe: Dense 3d
  reconstruction and pose estimation with convolutional neural networks for
  warehouse robots,'' in \emph{2019 European Conference on Mobile Robots
  (ECMR)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 1--6.

\bibitem{rad2017bb8}
M.~Rad and V.~Lepetit, ``Bb8: A scalable, accurate, robust to partial occlusion
  method for predicting the 3d poses of challenging objects without using
  depth,'' in \emph{Proceedings of the IEEE international conference on
  computer vision}, 2017, pp. 3828--3836.

\bibitem{hoang2020object}
D.-C. Hoang, A.~J. Lilienthal, and T.~Stoyanov, ``Object-rpe: Dense 3d
  reconstruction and pose estimation with convolutional neural networks,''
  \emph{Robotics and Autonomous Systems}, vol. 133, p. 103632, 2020.

\bibitem{doosti2020hope}
B.~Doosti, S.~Naha, M.~Mirbagheri, and D.~J. Crandall, ``Hope-net: A
  graph-based model for hand-object pose estimation,'' in \emph{Proc. IEEE/CVF
  Conf. Comput. Vis. Pattern Recognit.}, 2020, pp. 6608--6617.

\bibitem{lin2023harmonious}
Z.~Lin, C.~Ding, H.~Yao, Z.~Kuang, and S.~Huang, ``Harmonious feature learning
  for interactive hand-object pose estimation,'' in \emph{Proc. IEEE/CVF Conf.
  Comput. Vis. Pattern Recognit.}, 2023, pp. 12\,989--12\,998.

\bibitem{wang2023interacting}
R.~Wang, W.~Mao, and H.~Li, ``Interacting hand-object pose estimation via dense
  mutual attention,'' in \emph{Proc. IEEE/CVF Conf. Comput. Vis. Pattern
  Recognit.}, 2023, pp. 5735--5745.

\bibitem{woo2023survey}
T.~Woo, W.~Park, W.~Jeong, and J.~Park, ``A survey of deep learning methods and
  datasets for hand pose estimation from hand-object interaction images,''
  \emph{Computers \& Graphics}, vol. 116, pp. 474--490, 2023.

\bibitem{romero2022embodied}
J.~Romero, D.~Tzionas, and M.~J. Black, ``Embodied hands: Modeling and
  capturing hands and bodies together,'' \emph{arXiv preprint
  arXiv:2201.02610}, 2022.

\bibitem{son2022past}
Y.~H. Son, G.-Y. Kim, H.~C. Kim, C.~Jun, and S.~D. Noh, ``Past, present, and
  future research of digital twin for smart manufacturing,'' \emph{Journal of
  Computational Design and Engineering}, vol.~9, no.~1, pp. 1--23, 2022.

\bibitem{park2015spatial}
M.~K. Park, K.~J. Lim, M.~K. Seo, S.~J. Jung, and K.~H. Lee, ``Spatial
  augmented reality for product appearance design evaluation,'' \emph{Journal
  of Computational Design and Engineering}, vol.~2, no.~1, pp. 38--46, 2015.

\bibitem{gao20206d}
G.~Gao, M.~Lauri, Y.~Wang, X.~Hu, J.~Zhang, and S.~Frintrop, ``6d object pose
  regression via supervised learning on point clouds,'' in \emph{Proc.IEEE Int.
  Conf. Robot. Automat.}\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2020, pp.
  3643--3649.

\bibitem{guo2021efficient}
J.~Guo, X.~Xing, W.~Quan, D.-M. Yan, Q.~Gu, Y.~Liu, and X.~Zhang, ``Efficient
  center voting for object detection and 6d pose estimation in 3d point
  cloud,'' \emph{IEEE Transactions on Image Processing}, vol.~30, pp.
  5072--5084, 2021.

\bibitem{he2020pvn3d}
Y.~He, W.~Sun, H.~Huang, J.~Liu, H.~Fan, and J.~Sun, ``Pvn3d: A deep point-wise
  3d keypoints voting network for 6dof pose estimation,'' in \emph{Proc.
  IEEE/CVF Conf. Comput. Vis. Pattern Recognit.}, 2020, pp. 11\,632--11\,641.

\bibitem{hong2024rdpn6d}
Z.-W. Hong, Y.-Y. Hung, and C.-S. Chen, ``Rdpn6d: Residual-based dense
  point-wise network for 6dof object pose estimation based on rgb-d images,''
  in \emph{Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.}, 2024, pp.
  5251--5260.

\bibitem{lowe1999object}
D.~G. Lowe, ``Object recognition from local scale-invariant features,'' in
  \emph{Proceedings of the seventh IEEE international conference on computer
  vision}, vol.~2.\hskip 1em plus 0.5em minus 0.4em\relax Ieee, 1999, pp.
  1150--1157.

\bibitem{lepetit2005monocular}
V.~Lepetit, P.~Fua \emph{et~al.}, ``Monocular model-based 3d tracking of rigid
  objects: A survey,'' \emph{Foundations and Trends{\textregistered} in
  Computer Graphics and Vision}, vol.~1, no.~1, pp. 1--89, 2005.

\bibitem{xiang2017posecnn}
Y.~Xiang, T.~Schmidt, V.~Narayanan, and D.~Fox, ``Posecnn: A convolutional
  neural network for 6d object pose estimation in cluttered scenes,''
  \emph{arXiv preprint arXiv:1711.00199}, 2017.

\bibitem{kehl2017ssd}
W.~Kehl, F.~Manhardt, F.~Tombari, S.~Ilic, and N.~Navab, ``Ssd-6d: Making
  rgb-based 3d detection and 6d pose estimation great again,'' in
  \emph{Proceedings of the IEEE international conference on computer vision},
  2017, pp. 1521--1529.

\bibitem{tekin2018real}
B.~Tekin, S.~N. Sinha, and P.~Fua, ``Real-time seamless single shot 6d object
  pose prediction,'' in \emph{Proceedings of the IEEE conference on computer
  vision and pattern recognition}, 2018, pp. 292--301.

\bibitem{oberweger2018making}
M.~Oberweger, M.~Rad, and V.~Lepetit, ``Making deep heatmaps robust to partial
  occlusions for 3d object pose estimation,'' in \emph{Proceedings of the
  European conference on computer vision (ECCV)}, 2018, pp. 119--134.

\bibitem{park2019pix2pose}
K.~Park, T.~Patten, and M.~Vincze, ``Pix2pose: Pixel-wise coordinate regression
  of objects for 6d pose estimation,'' in \emph{Proceedings of the IEEE/CVF
  international conference on computer vision}, 2019, pp. 7668--7677.

\bibitem{hu2020single}
Y.~Hu, P.~Fua, W.~Wang, and M.~Salzmann, ``Single-stage 6d object pose
  estimation,'' in \emph{Proceedings of the IEEE/CVF conference on computer
  vision and pattern recognition}, 2020, pp. 2930--2939.

\bibitem{chen2020end}
B.~Chen, A.~Parra, J.~Cao, N.~Li, and T.-J. Chin, ``End-to-end learnable
  geometric vision by backpropagating pnp optimization,'' in \emph{Proceedings
  of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2020,
  pp. 8100--8109.

\bibitem{lepetit2009ep}
V.~Lepetit, F.~Moreno-Noguer, and P.~Fua, ``Ep n p: An accurate o (n) solution
  to the p n p problem,'' \emph{International journal of computer vision},
  vol.~81, pp. 155--166, 2009.

\bibitem{sun2021robust}
X.~Sun, J.~Zhou, W.~Zhang, Z.~Wang, and Q.~Yu, ``Robust monocular pose tracking
  of less-distinct objects based on contour-part model,'' \emph{IEEE
  Transactions on Circuits and Systems for Video Technology}, vol.~31, no.~11,
  pp. 4409--4421, 2021.

\bibitem{huang2021pixel}
H.~Huang, F.~Zhong, and X.~Qin, ``Pixel-wise weighted region-based 3d object
  tracking using contour constraints,'' \emph{IEEE Transactions on
  Visualization and Computer Graphics}, vol.~28, no.~12, pp. 4319--4331, 2021.

\bibitem{stoiber2020sparse}
M.~Stoiber, M.~Pfanne, K.~H. Strobl, R.~Triebel, and A.~Albu-Sch{\"a}ffer, ``A
  sparse gaussian approach to region-based 6dof object tracking,'' in
  \emph{Proceedings of the Asian Conference on Computer Vision}, 2020.

\bibitem{tian2022large}
X.~Tian, X.~Lin, F.~Zhong, and X.~Qin, ``Large-displacement 3d object tracking
  with hybrid non-local optimization,'' in \emph{European Conference on
  Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp.
  627--643.

\bibitem{garon2017deep}
M.~Garon and J.-F. Lalonde, ``Deep 6-dof tracking,'' \emph{IEEE transactions on
  visualization and computer graphics}, vol.~23, no.~11, pp. 2410--2418, 2017.

\bibitem{marougkas2020track}
I.~Marougkas, P.~Koutras, N.~Kardaris, G.~Retsinas, G.~Chalvatzaki, and
  P.~Maragos, ``How to track your dragon: A multi-attentional framework for
  real-time rgb-d 6-dof object pose tracking,'' in \emph{European Conference on
  Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020, pp.
  682--699.

\bibitem{manhardt2018deep}
F.~Manhardt, W.~Kehl, N.~Navab, and F.~Tombari, ``Deep model-based 6d pose
  refinement in rgb,'' in \emph{Proceedings of the European Conference on
  Computer Vision (ECCV)}, 2018, pp. 800--815.

\bibitem{li2018deepim}
Y.~Li, G.~Wang, X.~Ji, Y.~Xiang, and D.~Fox, ``Deepim: Deep iterative matching
  for 6d pose estimation,'' in \emph{Proceedings of the European Conference on
  Computer Vision (ECCV)}, 2018, pp. 683--698.

\bibitem{dosovitskiy2015flownet}
A.~Dosovitskiy, P.~Fischer, E.~Ilg, P.~Hausser, C.~Hazirbas, V.~Golkov, P.~Van
  Der~Smagt, D.~Cremers, and T.~Brox, ``Flownet: Learning optical flow with
  convolutional networks,'' in \emph{Proceedings of the IEEE international
  conference on computer vision}, 2015, pp. 2758--2766.

\bibitem{wen2020se}
B.~Wen, C.~Mitash, B.~Ren, and K.~E. Bekris, ``se (3)-tracknet: Data-driven 6d
  pose tracking by calibrating image residuals in synthetic domains,'' in
  \emph{2020 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2020, pp.
  10\,367--10\,373.

\bibitem{deng2021poserbpf}
X.~Deng, A.~Mousavian, Y.~Xiang, F.~Xia, T.~Bretl, and D.~Fox, ``Poserbpf: A
  rao--blackwellized particle filter for 6-d object pose tracking,'' \emph{IEEE
  Transactions on Robotics}, vol.~37, no.~5, pp. 1328--1342, 2021.

\bibitem{majcher20203d}
M.~Majcher and B.~Kwolek, ``3d model-based 6d object pose tracking on rgb
  images using particle filtering and heuristic optimization.'' in
  \emph{VISIGRAPP (5: VISAPP)}, 2020, pp. 690--697.

\bibitem{zhong2020seeing}
L.~Zhong, Y.~Zhang, H.~Zhao, A.~Chang, W.~Xiang, S.~Zhang, and L.~Zhang,
  ``Seeing through the occluders: Robust monocular 6-dof object pose tracking
  via model-guided video object segmentation,'' \emph{IEEE Robotics and
  Automation Letters}, vol.~5, no.~4, pp. 5159--5166, 2020.

\bibitem{wang2023deep}
L.~Wang, S.~Yan, J.~Zhen, Y.~Liu, M.~Zhang, G.~Zhang, and X.~Zhou, ``Deep
  active contours for real-time 6-dof object tracking,'' in \emph{Proceedings
  of the IEEE/CVF International Conference on Computer Vision}, 2023, pp.
  14\,034--14\,044.

\bibitem{vaswani2017attention}
A.~Vaswani, ``Attention is all you need,'' \emph{arXiv preprint
  arXiv:1706.03762}, 2017.

\bibitem{zhou2023deep}
J.~Zhou, K.~Chen, L.~Xu, Q.~Dou, and J.~Qin, ``Deep fusion transformer network
  with weighted vector-wise keypoints voting for robust 6d object pose
  estimation,'' in \emph{Proceedings of the IEEE/CVF International Conference
  on Computer Vision}, 2023, pp. 13\,967--13\,977.

\bibitem{hong2024transformer}
J.-X. Hong, H.-B. Zhang, J.-H. Liu, Q.~Lei, L.-J. Yang, and J.-X. Du, ``A
  transformer-based multi-modal fusion network for 6d pose estimation,''
  \emph{Information Fusion}, vol. 105, p. 102227, 2024.

\bibitem{li2023depth}
Z.~Li and I.~Stamos, ``Depth-based 6dof object pose estimation using swin
  transformer,'' in \emph{2023 IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE,
  2023, pp. 1185--1191.

\bibitem{periyasamy2023yolopose}
A.~S. Periyasamy, A.~Amini, V.~Tsaturyan, and S.~Behnke, ``Yolopose v2:
  Understanding and improving transformer-based 6d pose estimation,''
  \emph{Robotics and Autonomous Systems}, vol. 168, p. 104490, 2023.

\bibitem{liu2021swin}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo, ``Swin
  transformer: Hierarchical vision transformer using shifted windows,'' in
  \emph{Proceedings of the IEEE/CVF international conference on computer
  vision}, 2021, pp. 10\,012--10\,022.

\bibitem{gao2023visfusion}
H.~Gao, W.~Mao, and M.~Liu, ``Visfusion: Visibility-aware online 3d scene
  reconstruction from videos,'' in \emph{Proceedings of the IEEE/CVF Conference
  on Computer Vision and Pattern Recognition}, 2023, pp. 17\,317--17\,326.

\bibitem{huang2025visibility}
Z.~Huang, Y.~Shi, and M.~Gong, ``Visibility-aware pixelwise view selection for
  multi-view stereo matching,'' in \emph{International Conference on Pattern
  Recognition}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2025, pp.
  130--144.

\bibitem{chen2020visibility}
R.~Chen, S.~Han, J.~Xu, and H.~Su, ``Visibility-aware point-based multi-view
  stereo network,'' \emph{IEEE transactions on pattern analysis and machine
  intelligence}, vol.~43, no.~10, pp. 3695--3708, 2020.

\bibitem{carion2020end}
N.~Carion, F.~Massa, G.~Synnaeve, N.~Usunier, A.~Kirillov, and S.~Zagoruyko,
  ``End-to-end object detection with transformers,'' in \emph{European
  conference on computer vision}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2020, pp. 213--229.

\bibitem{lin2017feature}
T.-Y. Lin, P.~Doll{\'a}r, R.~Girshick, K.~He, B.~Hariharan, and S.~Belongie,
  ``Feature pyramid networks for object detection,'' in \emph{Proceedings of
  the IEEE conference on computer vision and pattern recognition}, 2017, pp.
  2117--2125.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in \emph{Proceedings of the IEEE conference on computer vision
  and pattern recognition}, 2016, pp. 770--778.

\bibitem{jaegle2021perceiver}
A.~Jaegle, F.~Gimeno, A.~Brock, O.~Vinyals, A.~Zisserman, and J.~Carreira,
  ``Perceiver: General perception with iterative attention,'' in
  \emph{International conference on machine learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2021, pp. 4651--4664.

\bibitem{hampali2020honnotate}
S.~Hampali, M.~Rad, M.~Oberweger, and V.~Lepetit, ``Honnotate: A method for 3d
  annotation of hand and object poses,'' in \emph{Proc. IEEE/CVF Conf. Comput.
  Vis. Pattern Recognit.}, 2020, pp. 3196--3206.

\bibitem{he2017mask}
K.~He, G.~Gkioxari, P.~Doll{\'a}r, and R.~Girshick, ``Mask r-cnn,'' in
  \emph{Proceedings of the IEEE international conference on computer vision},
  2017, pp. 2961--2969.

\bibitem{hinterstoisser2012model}
S.~Hinterstoisser, V.~Lepetit, S.~Ilic, S.~Holzer, G.~Bradski, K.~Konolige, and
  N.~Navab, ``Model based training, detection and pose estimation of
  texture-less 3d objects in heavily cluttered scenes,'' in \emph{Asian
  conference on computer vision}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2012, pp. 548--562.

\bibitem{bregier2017symmetry}
R.~Br{\'e}gier, F.~Devernay, L.~Leyrit, and J.~L. Crowley, ``Symmetry aware
  evaluation of 3d object detection and pose estimation in scenes of many parts
  in bulk,'' in \emph{Int. Conf. Comput. Vis. Worksh.}, 2017, pp. 2209--2218.

\bibitem{castro2023crt}
P.~Castro and T.-K. Kim, ``Crt-6d: Fast 6d object pose estimation with cascaded
  refinement transformers,'' in \emph{Proceedings of the IEEE/CVF Winter
  Conference on Applications of Computer Vision}, 2023, pp. 5746--5755.

\bibitem{he2021ffb6d}
Y.~He, H.~Huang, H.~Fan, Q.~Chen, and J.~Sun, ``Ffb6d: A full flow
  bidirectional fusion network for 6d pose estimation,'' in \emph{Proc.
  IEEE/CVF Conf. Comput. Vis. Pattern Recognit.}, 2021, pp. 3003--3013.

\bibitem{stoiber2022srt3d}
M.~Stoiber, M.~Pfanne, K.~H. Strobl, R.~Triebel, and A.~Albu-Sch{\"a}ffer,
  ``Srt3d: A sparse region-based 3d object tracking approach for the real
  world,'' \emph{International Journal of Computer Vision}, vol. 130, no.~4,
  pp. 1008--1030, 2022.

\bibitem{labbe2020cosypose}
Y.~Labb{\'e}, J.~Carpentier, M.~Aubry, and J.~Sivic, ``Cosypose: Consistent
  multi-view multi-object 6d pose estimation,'' in \emph{Computer Vision--ECCV
  2020: 16th European Conference, Glasgow, UK, August 23--28, 2020,
  Proceedings, Part XVII 16}.\hskip 1em plus 0.5em minus 0.4em\relax Springer,
  2020, pp. 574--591.

\end{thebibliography}
